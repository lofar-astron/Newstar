% file lsq.tex : Least Squares in Newstar

% History:
%       WNB 95....
%       JPH 951127      Changes to make compatible with n_doc

%%\documentclass[10pt,a4paper]{article}
% []:titlepage,leqno,fleqn,11pt,12pt,twoside,twocolumn,landscape
% {}:report,letter

% LATEX_PREAMBLE_A4.TEX: Latex template
%%\setlength{\topmargin}{-15mm}
%\setlength{\textheight}{250mm}
%\setlength{\textwidth}{140mm}
%\setlength{\oddsidemargin}{0mm}
%\setlength{\evensidemargin}{0mm}
\setlength{\unitlength}{1mm}
\setlength{\parindent}{0mm}
\setlength{\parskip}{\medskipamount}
%\setlength{\parsep}{\smallskipamount}

\pagestyle{plain}                     % only a page number at the foot
%{}:plain,empty,headings,myheadings
%\markboth{lefthead}{righthead}
%\markright{righthead}

%\makeglossary
%\makeindex

% End of preamble.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{document}                       %%%%% start of actual document %%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\LSQ}{{\em LSQ}}
\newcommand{\SVD}{{\em SVD}}
\newcommand{\Cond}{{\em condition}}
\newcommand{\Weight}{{\em weight}}
\newcommand{\Known}{{\em measured}}
\newcommand{\Sol}{{\em solution}}
\newcommand{\Type}{{\em type}}
\newcommand{\Error}{{\em error}}
\newcommand{\Covar}{{\em covariance}}
\newcommand{\Xsd}{{\em uncertainties}}
\newcommand{\Mean}{{\em sd}}
\newcommand{\Fit}{{\em goodness}}
\newcommand{\Rank}{{\em rank}}
\newcommand{\Prec}{{\em collinearity}}
\newcommand{\Nconst}{{\em n-constraint}}
\newcommand{\Constraint}{{\em constraints}}
\newcommand{\Real}{{\sc real}}
\newcommand{\Int}{{\sc integer}}
\newcommand{\Complex}{{\sc complex}}
\newcommand{\Logic}{{\sc logical}}
\newcommand{\Mn}{{\vspace{-0.5em}}}
 \renewcommand{\mathbf}[1]{\mbox{$\boldmath #1$}}

\chapter{Least Squares in Newstar}
\\
{\it Contributed by W.N. Brouw, 15 April, 1995 --- Version 3}
\tableofcontents


\section{Introduction}
\label{s-Intro}

Tryimg to find a more stable non-linear least squares method (\LSQ) than the
one currently used in Newstar, I found another few areas that could be added
or improved in the existing routines. In the end I made the following
changes:
\begin{itemize}
\item improved error estimates for solved variables \Mn
\item included support for user defined constraints \Mn
\item support for more stable non-linear solutions \Mn
\item changed the user interface to routines (they are now called WNML\ldots\
rather than WNMI\ldots\ , WNMY\ldots\ , WNMX\ldots\  or WNMZ\ldots) \Mn
\end{itemize}
In addition the present document describes the usage and background of the
different routines.

Least squares solutions in Newstar have the following general
background:
\begin{enumerate}
\item all are based on creating normal equations from an, initially unknown,
number of condition equations \Mn
\item the actual \LSQ-object is a symmetric (or Hermitian) matrix \Mn
\item matrix inversions are done using in-place Cholesky methods where
possible: it is for
standard use the fastest, least memory consuming and a stable method. In cases
where the inverse matrix is needed, the method uses resources of the same
order as full LU-decomposition. \Mn
\item input/output to the \LSQ-object is done in single precision, internally
all calculations are done in double precision \Mn
\item all routines using the \LSQ\ package should include the
{{\sc lsq}\_{\sc o}\_{\sc def}} file \Mn
\item complex numbers are assumed to be contiguous pairs of real numbers with
the real part being the first \Mn
\end{enumerate}

The following terminology is used throughout:
\begin{list}{1}{\setlength{\labelwidth}{6em}}
\item[$n$] number of unknowns to be solved \Mn
\item[$m$] number of simultaneous knowns \Mn
\item[$N$] number of condition equations \Mn
\item[$\chi^2$] merit function \Mn
\item[$z^*$] complex conjugate of $z$  \Mn
\item[$z_{\Re}$] real part of $z$ \Mn
\item[$z_{\Im}$] imaginary part of $z$ \Mn
\item[$\mathbf{x}$] column vector of unknowns $x_{0},\ldots,x_{n-1}$ \Mn
\item[$\mathbf{a}_{i}$] vector of factors $a_{0,i},\ldots,a_{n-1,i}$ in
condition equation $i$ \\( $i=0,\ldots,N-1$ ) \Mn
\item[$\mathbf{C}$] the $N\times n$ array of condition equations \Mn
\item[$\mathbf{A}$] $n\times n$ array: normal equations matrix \Mn
\item[$\mathbf{L}$] $n$ column vector: right-hand side normal equations  \Mn
\item[$y_{i}$] model value for condition equation $i$ (
$i=0,\ldots,N-1$ ) \Mn
\item[$l_{i}$] measured value for condition equation $i$ (
$i=0,\ldots,N-1$ ) \Mn
\item[$\sigma_{i}$] standard deviation for condition equation $i$ (
$i=0,\ldots,N-1$ ) \Mn
\item[$w_{i}$] weight for condition equation $i$ ($w_{i}=1/\sigma_{i}^2$) \Mn
\item[${[}ab{]}$] shorthand for $\sum_{i=0}^{N-1} w_{i} a_{i} b_{i}$ \Mn
\end{list}

The condition equations can, with the above definitions, be written in one of
the following ways:

\begin{equation}
	\mathbf{a}_{i}\cdot\mathbf{x}  =  l_{i} \hspace{2cm} i=0,\ldots,N-1
\end{equation}

or as:

\begin{eqnarray}
	\sum_{k=0}^{n-1} a_{ik}x_{k}  =  l_{i} \hspace{2cm} i=0,\ldots,N-1
\end{eqnarray}

or as:

\begin{equation}
	\mathbf{C\cdot x}  =  \mathbf{l}
\end{equation}

The normal matrix is defined as:

\begin{equation}
	\mathbf{A} = \mathbf{C}^{T}\cdot\mathbf{Q}^{-1}\cdot\mathbf{C}
\end{equation}
resulting in the normal equations:
\begin{equation}
	\mathbf{A}\cdot\mathbf{x} = \mathbf{L}
\end{equation}
where $\mathbf{L}=\mathbf{C^{T}}\cdot\mathbf{l}$ and
$\mathbf{Q}$ is the covariance matrix of the observations. In Newstar only
covariance matrices with the same value in each column $i$ (the `weight'
$w_{i}$) are considered.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Linear equations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Real}
The merit function we want to minimise is:

\begin{eqnarray}
	\chi^{2} = \sum_{i=0}^{N-1}
	{\left[ \frac{l_{i}-y_{i}}{\sigma_{i}} \right]}^{2}
\label{.e.chir}
\end{eqnarray}

For the minimum of $\chi^{2}$ holds:

\begin{equation}
	\frac{\partial \chi^{2}}{\partial a_{k}} = 0
	\hspace{2cm} k=0,\ldots,n-1
\end{equation}

which leads to the following set of normal equations:

\begin{equation}
	\sum_{i=0}^{N-1} \frac{\left[ l_{i} - y_{i}\right]}{\sigma_{i}^{2}}
	\frac{\partial y_{i}}{\partial a_{k}} = 0
	\hspace{2cm} k=0,\ldots,n-1
\end{equation}

or in matrix form:

\begin{equation}
	\left( \begin{array}{cccc}
	\left[ a_{0}a_{0}\right] & \left[ a_{0}a_{1}\right] &
		 \cdots & \left[ a_{0}a_{n-1}\right] \\
	\left[ a_{1}a_{0}\right] & \left[ a_{1}a_{1}\right] &
		\cdots & \left[ a_{1}a_{n-1}\right] \\
	\vdots       & \vdots       & \ddots & \vdots \\
	\left[ a_{n-1}a_{0}\right] & \left[ a_{n-1}a_{1}\right] &
		\cdots & \left[ a_{n-1}a_{n-1}\right]
	       \end{array} \right)
	\cdot \mathbf{x} =
	\left( \begin{array} {c}
	\left[ a_{0}l\right] \\
	\left[ a_{1}l\right] \\
	\vdots \\
	\left[ a_{n-1}l\right]
	       \end{array} \right)
			\label{.e.solr}
\end{equation}

or:

\begin{equation}
	\mathbf{A}\cdot\mathbf{x} = \mathbf{L}
\end{equation}
This symmetric set of equations can be solved, if the matrix is positive
definite, i.e. if there are no dependencies between the columns. The solution
is given by:

\begin{equation}
	\mathbf{x} = \mathbf{A}^{-1}\cdot\mathbf{L}
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Errors}
\label{.ss.errors}

After solution for the unknowns $\mathbf{x}$, $\chi^{2}$ as defined in
\eqref{.e.chir} can be directly calculated if we rewrite it as:
\begin{equation}
	\chi^{2} = [ll] - 2\sum_{k=0}^{n-1}[a_{k}l]x_{k} +
			\sum_{i=0}^{N-1}  w_{i}y_{i}^{2}
\label{.e.chis2}
\end{equation}
Noting that $y_{i}=\sum_{k=0}^{n-1}a_{k}x_{k}$ and using equation
\eqref{.e.solr} to note
that $[a_{i}l]=\sum_{k=0}^{n-1} [a_{i}a_{k}]x_{k}$, we can rewrite
\eqref{.e.chis2} as:
\begin{equation}
	\chi^{2} = [ll] -  \sum_{k=0}^{n-1} x_{k}[a_{k}l]
\label{.e.chis3}
\end{equation}
The $\chi^{2}$ could be used to assess the goodness of fit if the actual
$\sigma_{i}$'s were known, and the errors are normal distributed. In general the
actual values of $\sigma_{i}$ are not known, and often the distribution is not
normal (.e.g. if we solve for logarithmic values). An estimate of the standard
deviation can be made by:
\begin{equation}
	\sigma^{2}=
	\frac{\left[ \left( l_{i}-y_{i}\right)^{2}\right]}{N-n}
\end{equation}
which can be estimated by:
\begin{equation}
	\sigma_{o}^{2}=\frac{\chi^{2}}{N-n}
\end{equation}
to give `an error per observation'. The `error per unit weight', or the
standard deviation, can be expressed as:
\begin{equation}
	\sigma_{w}^{2}=\frac{\chi^{2}}{[1]}\frac{N}{N-n}
\end{equation}

The uncertainty in the solution $x_{i}$ can be expressed as:
\begin{equation}
	\sigma^{2}\left(x_{i}\right) =
		\sum_{k=1}^{N-1}\sigma_{k}^{2}
	{\left(\frac{\partial{x_{i}}}{\partial{y_{k}}}\right)}^{2}
\end{equation}
Since
\begin{equation}
	x_{i}=\sum_{k=0}^{n-1}{\left(\mathbf{A}^{-1}\right)}_{ik}
		\left[a_{k}l\right]
\end{equation}
we have:
\begin{equation}
	{\frac{\partial{x_{i}}}{\partial{y_{k}}}}=
	\sum_{j=0}^{n-1}{\left(\mathbf{A}^{-1}\right)}_{ij}
		\frac{a_{kj}}{\sigma_{k}^{2}}
\end{equation}
leading to:
\begin{equation}
	\sigma^{2}\left(x_{i}\right) =
		\sum_{k=0}^{n-1}\sum_{l=0}^{n-1}
		{\left(\mathbf{A}^{-1}\right)}_{ik}
		{\left(\mathbf{A}^{-1}\right)}_{il}
		\left[\sum_{j=0}^{N-1}
			\frac{a_{kj}a_{lj}}{\sigma_{j}^{2}}\right]
\end{equation}
Doing the sums, this equation reduces to:
\begin{equation}
	\sigma^{2}\left(x_{i}\right) =
		{\left(\mathbf{A}^{-1}\right)}_{ii}
\end{equation}
If the $\sigma_{i}$ was not known originally, the estimate of the standard
uncertainties in the unknowns $\mathbf{x}$ are:
\begin{equation}
	\sigma\left(x_{i}\right) = \sigma_{o}
		\sqrt{{\left(\mathbf{A}^{-1}\right)}_{ii}}
\label{.e.sigx}
\end{equation}

If the uncertainties in the unknowns are wanted, Newstar calculates the
inverse matrix $\mathbf{A}^{-1}$ by backsubstitution of the identity matrix,
and the uncertainties by \eqref{.e.sigx}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Newstar calls}
\label{.ss.ncalls}

Real \LSQ\ in Newstar is implemented by the following calls:
\begin{enumerate}
\item generate an \LSQ-object with:\\
	\Logic\ WNMLGA(\LSQ, \Type, $n$\ [, $m$]) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \Int, return pointer to created \LSQ-object
(if {\em .true.}) \Mn
	\item[\Type] coded \Int; coded as: 0 or
{{\sc lsq}\_{\sc t}\_{\sc real}}\ [+\ {{\sc lsq}\_{\sc t}\_{\sc multiple}}].
The second part indicates that multiple ($m > 1$) simultaneous equations are
requested.  \Mn
	\item[$n$]  \Int, number of unknowns \Mn
	\item[$m$]  \Int, number of simultaneous equations if
{{\sc lsq}\_{\sc t}\_{\sc multiple}} specified (default one) \Mn
\end{list}
\item generate normal equations from the condition equations with successive
calls to:\\
	CALL WNMLMN(\LSQ, \Type, \Cond, \Weight, \Known) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Type] $0$ or {{\sc lsq}\_{\sc c}\_{\sc real}} to indicate
that the condition equations are real \Mn
	\item[\Cond] factors in condition equation as \Real($0:n-1$) \Mn
	\item[\Weight] \Real, weight of condition equation ($w=1/\sigma^2$).
Note that for the best arithmetic performance, the $w_{i}$ are best
normalised to a maximum value of one. \Mn
	\item[\Known] measured value(s) as \Real($0:m-1$) \Mn
\end{list}
\item triangularise the normal equations matrix $\mathbf{A}$ with:\\
	\Logic\ WNMLTN(\LSQ) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
\end{list}
The value of WNMLTN is {\em .false.} if the matrix $\mathbf{A}$ is not
invertable. Note that if an unknown does not appear in any condition equation
with a non-zero coefficient (i.e. if the corresponding $A_{ii}
\equiv 0$) WNMLTN assumes a zero solution for the corresponding unknown. The
check on dependency between equations is done with a default precision of
$10^{-6}$. This precision can be \textref{changed}{.ss.specc}).
\item obtain the solution by back substitution with:\\
	CALL WNMLSN(\LSQ,\Sol,\Error,\Mean) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Sol] solution $\mathbf{x}$ as \Real($0:n-1,0:m-1$) \Mn
	\item[\Error] adjustment error per unit weight ($\sigma_{w}$)as
\Real($0:m-1$) \Mn
	\item[\Mean] standard deviation ($\sigma_{o}$) as \Real($0:m-1$) \Mn
\end{list}
\item obtain the covariance matrix or something similar with:\\
	CALL WNMLME(\LSQ,\Xsd) or:\\
	CALL WNMLCV(\LSQ,\Covar) or:\\
	CALL WNMLIN(\LSQ) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Xsd] the uncertainties in the unknowns $\mathbf{x}$ as
\Real($0:n-1,0:m-1$) \Mn
	\item[\Covar] the covariance (inverse) matrix of the solution, as
\Real($0:n-1,0:n-1$) \Mn
\end{list}
	WNMLIN will calculate the covariance matrix internally only. In all
three cases the covariance matrix will overwrite the normal array, and it
will be used, rather than back substitution, in WNMLSN if that routine is
called after one of the inversion ones.
\item free \LSQ-object with: \\
	CALL WNMLFA(\LSQ)
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Additional Newstar calls}
\label{.ss.specc}

A number of other calls are available to aid, especially, re-use of the
\LSQ-object:

\begin{description}
	\item[--] re-initialise the \LSQ-object for re-use with: \\
CALL WNMLIA(\LSQ, \Type\ [, \Prec]) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Type] coded \Int, coded as a combination of:
\begin{description}
	\item[--] 0: default, equal to {{\sc lsq}\_{\sc i}\_{\sc all}} \Mn
	\item[--] {{\sc lsq}\_{\sc i}\_{\sc norm}}: re-initialise the
`unknown' part of the object (i.e. the normal array $\mathbf{A}$) \Mn
	\item[--] {{\sc lsq}\_{\sc i}\_{\sc known}}: re-initialise the
`known' part of the object (i.e. the vector ${\mathbf L}$) \Mn
	\item[--] {{\sc lsq}\_{\sc i}\_{\sc sol}}: equal to
{\sc norm}\ +\ {\sc known} \Mn
	\item[--] {{\sc lsq}\_{\sc i}\_{\sc nonlin}}: re-initialise the
non-linear part of the object \Mn
	\item[--] {{\sc lsq}\_{\sc i}\_{\sc all}}: equal to
{\sc sol}\ +\ {\sc nonlin} \Mn
	\item[--] {{\sc lsq}\_{\sc i}\_{\sc prec}}: set the internal check
precision to \Prec \Mn
\end{description}
	\item[\Prec] precision factor to be used (\Real). Only used if
{{\sc lsq}\_{\sc i}\_{\sc prec}} set. Note that the default internal value is
$10^{-6}$.  \Mn
\end{list}
	\item[--] re-create (parts of) the normal equations with successive
calls to:\\
	CALL WNMLMN(\LSQ, \Type, \Cond, \Weight, \Known) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Type] the standard {{\sc lsq}\_{\sc c}\_{\sc real}} etc can be
used, with in addition one of the following:
\begin{description}
	\item[--] {{\sc lsq}\_{\sc c}\_{\sc nonorm}}: do not update the
normal array ($\mathbf{A}$) \Mn
	\item[--] {{\sc lsq}\_{\sc c}\_{\sc noknown}}: do not update the
`known' part of the normal equations ($\mathbf{L}$) \Mn
\end{description}
	\item[\Cond] factors in condition equation as \Real($0:n-1$) \Mn
	\item[\Weight] \Real, weight of condition equation ($w=1/\sigma^2$)
Note that for the best arithmetic performance, the $w_{i}$ are best
normalised to a maximum value of one. \Mn
	\item[\Known] measured value(s) as \Real($0:m-1$) \Mn
\end{list}
\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Complex}

The merit function we want to minimise in this case is:

\begin{equation}
	\chi^{2} = \sum_{i=0}^{N-1}
	{\left[ \frac{l_{i}-y_{i}}{\sigma_{i}} \right]}
	{\left[ \frac{l_{i}-y_{i}}{\sigma_{i}} \right]}^{*}
		\label{.e.chic}
\end{equation}

Differentiating $\chi^{2}$ leads to the following set of normal equations:

\begin{equation}
	\left( \begin{array}{cccc}
	\left[ a_{0}^{*}a_{0}\right] & \left[ a_{0}^{*}a_{1}\right] &
		 \cdots & \left[ a_{0}^{*}a_{n-1}\right] \\
	\left[ a_{1}^{*}a_{0}\right] & \left[ a_{1}^{*}a_{1}\right] &
		\cdots & \left[ a_{1}^{*}a_{n-1}\right] \\
	\vdots       & \vdots       & \ddots & \vdots \\
	\left[ a_{n-1}^{*}a_{0}\right] & \left[ a_{n-1}^{*}a_{1}\right] &
		\cdots & \left[ a_{n-1}^{*}a_{n-1}\right]
	       \end{array} \right)
	\cdot \mathbf{x} =
	\left( \begin{array} {c}
	\left[ a_{0}^{*}l\right] \\
	\left[ a_{1}^{*}l\right] \\
	\vdots \\
	\left[ a_{n-1}^{*}l\right]
	       \end{array} \right)
			\label{.e.solc}
\end{equation}

The normal matrix is Hermitian. It can be solved by Choleski methods.
However, internally the matrix is converted to a real form. Although this has
an, in general, small memory penalty, it has no influence on CPU time, and
makes it possible to use the same routines for complex and real solutions.
The conversion to real is done by splitting each element $A_{ij}$ of the
normal matrix into ${A_{\Re}}_{ij}+\imath{A_{\Im}}_{ij}$ and replacing it by:

\begin{equation}
	A_{ij}=\left( \begin{array}{rr}
		      {A_{ij}}_{\Re} & -{A_{ij}}_{\Im} \\
		      {A_{ij}}_{\Im} & {A_{ij}}_{\Re}
		      \end{array} \right)
\label{.e.comnor}
\end{equation}

and simular replacements for the vector elements $x_{i}$ and $L_{i}$ as:

\begin{equation}
	x_{i}=\left( \begin{array} {r}
		     {x_{i}}_{\Re} \\
			{x_{i}}_{\Im}
		     \end{array} \right)
\end{equation}
and:
\begin{equation}
	L_{i}=\left( \begin{array} {r}
		     {L_{i}}_{\Re} \\
			{L_{i}}_{\Im}
		     \end{array} \right)
\end{equation}


Another reason for solving real rather than complex equations is given in the
next section.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Separable complex}
\label{.ss.sepc}

In cases where both the unknowns $\mathbf{x}$ and their complex conjugates
$\mathbf{x}^{*}$ appear in the condition equations, differentiating the merit
function \eqref{.e.chic} will not produce a symmetric or Hermitian
normal matrix, since there exists no linear relation between $x_{i}$ and
$x^{*}_{i}$. We could, of course, solve for $2n$ complex equations with added
constraints that the sum of even and odd unknowns must be real, and their
difference imaginary, but this will lead to $4n$ complex equations.

If, however, we consider each complex unknown as two real unknowns (i.e.
${x_{i}}_{\Re}$ and ${x_{i}}_{\Im}$) then differentiating \eqref{.e.chic}
produces the
following symmetric set of $2n$ real equations:

\begin{displaymath}
	\left( \begin{array}{ccccc}
	{\left[ {a_{0}}^{*}a_{0}\right]}_{\Re} &
	{\left[ {a_{1}}^{*}a_{0}\right]}_{\Im} &
	{\left[ {a_{2}}^{*}a_{0}\right]}_{\Re} &
	\cdots &
	{\left[ {a_{2n-1}}^{*}a_{0}\right]}_{\Im}  \\
	-{\left[ {a_{0}}^{*}a_{1}\right]}_{\Im} &
	{\left[ {a_{1}}^{*}a_{1}\right]}_{\Re} &
	-{\left[ {a_{2}}^{*}a_{1}\right]}_{\Im} &
	\cdots &
	{\left[ {a_{2n-1}}^{*}a_{1}\right]}_{\Re} \\
	\vdots       & \vdots & \vdots      & \ddots & \vdots \\
	-{\left[ {a_{0}}^{*}a_{2n-1}\right]}_{\Im} &
	{\left[ {a_{1}}^{*}a_{2n-1}\right]}_{\Re} &
	-{\left[ {a_{2}}^{*}a_{2n-1}\right]}_{\Im} &
	\cdots &
	{\left[ {a_{2n-1}}^{*}a_{2n-1}\right]}_{\Re}
	       \end{array} \right) \cdot
\end{displaymath}
\begin{equation}
	\hspace{4cm} \cdot \left( \begin{array} {c}
		     {x_{0}}_{\Re} \\
			{x_{0}}_{\Im} \\
			{x_{1}}_{\Re} \\
			\vdots \\
			{x_{n-1}}_{\Im} \\
		     \end{array} \right) =
	\left( \begin{array} {c}
	{\left[ {a_{0}}^{*}l\right]}_{\Re} \\
	{\left[ {a_{1}}^{*}l\right]}_{\Im} \\
	{\left[ {a_{2}}^{*}l\right]}_{\Re} \\
	\vdots \\
	{\left[ {a_{2n-1}}^{*}l\right]}_{\Im}
	       \end{array} \right)
			\label{.e.solsc}
\end{equation}

A number of special cases can be distinguished.

In the `normal' complex case (previous section), $a_{2i}\equiv a_{2i+1}$, and
\eqref{.e.solsc} reduces to \eqref{.e.comnor}.

If all $a_{2i}$ and $a_{2i+1}$ are real, but specified, e.g., as a complex
number, \eqref{.e.solsc} deteriorates into:

\begin{displaymath}
	\left( \begin{array}{ccccc}
	\left[ {a_{0}}_{\Re}{a_{0}}_{\Re}\right] & 0 &
		\left[ {a_{0}}_{\Re}{a_{1}}_{\Re}\right] &  \cdots & 0 \\
	0 & \left[ {a_{0}}_{\Im}{a_{0}}_{\Im} \right] & 0 &
		\cdots & \left[ {a_{0}}_{\Im}{a_{n-1}}_{\Im}\right] \\
	\left[ {a_{1}}_{\Re}{a_{0}}_{\Re}\right] & 0 &
		 \left[ {a_{1}}_{\Re}{a_{1}}_{\Re}\right] & \cdots & 0 \\
	\vdots       & \vdots & \vdots      & \ddots & \vdots \\
	0 & \left[ {a_{n-1}}_{\Im}{a_{0}}_{\Im}\right] & 0 &
		\cdots & \left[ {a_{n-1}}_{\Im}{a_{n-1}}_{\Im} \right]
	       \end{array} \right) \cdot
\end{displaymath}
\begin{equation}
	\hspace{4cm} \cdot \left( \begin{array} {c}
		     {x_{0}}_{\Re} \\
			{x_{0}}_{\Im} \\
			{x_{1}}_{\Re} \\
			\vdots \\
			{x_{n-1}}_{\Im} \\
		     \end{array} \right) =
	\left( \begin{array} {c}
	\left[ {a_{0}}_{\Re}l_{\Re}\right] \\
	\left[ {a_{0}}_{\Im}l_{\Im}\right] \\
	\left[ {a_{1}}_{\Re}l_{\Re}\right] \\
	\vdots \\
	\left[ {a_{n-1}}_{\Im}l_{\Im}\right]
	       \end{array} \right)
			\label{.e.solscr}
\end{equation}

Note that in this case there is a true separation of the real and imaginary
parts of the different unknowns, and two separate real solutions with each
$n$ unknowns will produce exactly the same result.

The full and special cases are all catered for in the Newstar routines.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Errors}

Using arguments comparable to \textref{those in}{.ss.errors}, we can get
\eqref{.e.chis3} for the complex case as:
\begin{equation}
	\chi^{2} = [ll^{*}] -
\sum_{k=0}^{n-1} \left( {x_{k}}_{\Re}{\left[ a_{2k}^{*}l \right]}_{\Re} +
{x_{k}}_{\Im}{\left[ a_{2k+1}^{*}l \right]}_{\Im}  \right)
\label{.e.chis4}
\end{equation}
with the $a$'s and $x$'s as defined in \eqref{.e.solscr}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Newstar calls}
\label{.ss.ccalls}

Complex \LSQ\ in Newstar is implemented as a real \LSQ\ with $2n$
unknowns. All calls are identical to those with
\textref{those in}{.ss.ncalls}, but with different \Type\ and some \Complex\
rather than
\Real\ arguments:
\begin{enumerate}
\item generate an \LSQ-object with:\\
	\Logic\ WNMLGA(\LSQ, \Type, $n$\ [, $m$]) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \Int, return pointer to created \LSQ-object
(if {\em .true.}) \Mn
	\item[\Type] coded \Int; coded as:
{{\sc lsq}\_{\sc t}\_{\sc complex}}\ [+\ {{\sc lsq}\_{\sc t}\_{\sc multiple}}].
The second part indicates that multiple ($m > 1$) simultaneous equations are
requested.  \Mn
	\item[$n$]  \Int, number of (complex) unknowns \Mn
	\item[$m$]  \Int, number of simultaneous equations if
{{\sc lsq}\_{\sc t}\_{\sc multiple}} specified (default one) \Mn
\end{list}
\item generate normal equations from the condition equations with successive
calls to:\\
	CALL WNMLMN(\LSQ, \Type, \Cond, \Weight, \Known) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Type] coded \Int, coded as:
\begin{description}
	\item[--] 0: default, equal to {{\sc lsq}\_{\sc c}\_{\sc complex}} \Mn
	\item[--] {{\sc lsq}\_{\sc c}\_{\sc complex}}: coefficients in \Cond\
are $n$ complex numbers for $n$ complex unknowns \Mn
	\item[--] {{\sc lsq}\_{\sc c}\_{\sc real}}: coefficients in \Cond\
are $2n$ real numbers for $n$ complex unknowns. Each pair are the
coefficients for the real and imaginary parts of each unknown \Mn
	\item[--] {{\sc lsq}\_{\sc c}\_{\sc dcomplex}}: coefficients in \Cond\
are $2n$ complex numbers for $n$ complex unknowns. Each pair are the
coefficients for the real and imaginary parts of each unknown \Mn
	\item[--] {{\sc lsq}\_{\sc c}\_{\sc ccomplex}}: coefficients in \Cond\
are $2n$ complex numbers for $n$ complex unknowns. Each pair are the
coefficients for each unknown and its conjugate \Mn
\end{description}
	\item[\Cond] factors in condition equation as \\
\Real($0:2n-1$) or as
\Complex($0:n-1$) or as \Complex($0:2n-1$), depending on \Type \Mn
	\item[\Weight] \Real, weight of condition equation ($w=1/\sigma^2$).
Note that for the best arithmetic performance, the $w_{i}$ are best
normalised to a maximum value of one. \Mn
	\item[\Known] measured value(s) as \Complex($0:m-1$) \Mn
\end{list}
\item triangularise the normal equations matrix $\mathbf{A}$ with:\\
	\Logic\ WNMLTN(\LSQ) with:
\item obtain the solution by back substitution with:\\
	CALL WNMLSN(\LSQ,\Sol,\Error,\Mean) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Sol] solution $\mathbf{x}$ as \Complex($0:n-1,0:m-1$) \Mn
	\item[\Error] adjustment error per unit weight ($\sigma_{w}$)as
\Real($0:m-1$) \Mn
	\item[\Mean] standard deviation ($\sigma_{o}$) as \Real($0:m-1$) \Mn
\end{list}
\item obtain the covariance matrix or something similar with:\\
	CALL WNMLME(\LSQ,\Xsd) or:\\
	CALL WNMLCV(\LSQ,\Covar) or:\\
	CALL WNMLIN(\LSQ) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Xsd] the uncertainties in the unknowns $\mathbf{x}$ as
\Complex($0:n-1,0:m-1$). Note that in actual fact the errors are for the real
and imaginary parts only. True errors for the complex unknowns will be
$\sqrt{\frac{x_{\Im}^{2}\sigma_{\Im}^{2}+x_{\Re}^{2}\sigma_{\Re}^{2}}
{xx^{*}}}$ \Mn
	\item[\Covar] the covariance (inverse) matrix of the solution, as
\Real($0:2n-1,0:2n-1$) \Mn
\end{list}
	WNMLIN will calculate the covariance matrix internally only. In all
three cases the covariance matrix will overwrite the normal array, and it
will be used, rather than back substitution, in WNMLSN if that routine is
called after one of the inversion ones.
\item free \LSQ-object with: \\
	CALL WNMLFA(\LSQ)
\end{enumerate}

The same additional calls to re-use an (\textref{\LSQ-object}{.ss.specc}),
with the same arguments,
are available as for the real case. The type and number of \Cond\ are, of
course, dependent on the \Type\ of solution (real or complex) and \Type\ of
condition equations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dependant linear equations}

If there are not enough independent condition equations, the normal matrix
$\mathbf{A}$ cannot be inverted, and a call to WNMLTN will fail with a {\em
.false.} return value.

The equations could still be solved if some additional `constraint' equations
would be introduced. In the more complex cases the precise, let alone the
best, form for these additional equations is difficult to determine (e.g. the
redundancy situation in Westerbork).

A method known as `Single value decomposition' (\SVD) can be used to obtain
the minimal set of orthogonal equations that have to be added to solve the
\LSQ\ problem. Several implementations exist in the literature.

In general we can distinguish three types of constrained equations:
\begin{itemize}
	\item the minimum number of sufficient constraint equations are known
to be able to solve a system of equations \Mn
	\item constraints are used to add additional information (e.g. the
sum of angles of a triangle) \Mn
	\item no actual constraint equations are known \Mn
\end{itemize}
All three cases are handled in Newstar, the first two in the same way.

The general constraint situation arises from the use of Lagrange
multiplicators. Assume that in addition to the condition equations, with
measured values, we have a set of $p$ rigorous equations:
\begin{equation}
	\phi_i(\mathbf{x})=0 \hspace{1cm} i=0,\ldots,p-1
\label{.e.lag}
\end{equation}
We must therefore make $\chi^{2}$ minimal, subject to the set of
\eqref{.e.lag}, or:
\begin{equation}
	\sum_{i=0}^{n-1}\frac{\partial \chi^{2}}{\partial x_{i}}dx_{i}=0
\end{equation}
subject to the conditions:
\begin{equation}
	\sum_{i=0}^{n-1}\frac{\partial \phi_{k}}{\partial x_{i}}dx_{i}
		=0 \hspace {1cm} k=0,\dots,p-1
\end{equation}
which leads to a set of $n+p$ equations:
\begin{equation}
	\frac{\partial \chi^{2}}{\partial x_{i}} +
	\sum_{k=0}^{p-1}\lambda_{k}\frac{\partial \phi_{k}}{\partial x_{i}}=0
	\hspace{1cm} i=0,\ldots,n-1
\label{.e.lag2}
\end{equation}
together with the \eqref{.e.lag}.

Note that in Newstar I have chosen for having constraint equations linear in
the unknowns, with a zero value. In cases where this is not adequate (e.g.
$x+y+z=360$) a simple linear transformation will suffice to make it e.g.
$x'+y'+z'=0$.

Defining the second term in \eqref{.e.lag2} as $B_{ik}$, we can write our
expanded set of normal equations as:
\begin{equation}
	\left(\begin{array} {cc}
	      \mathbf{A} & \mathbf{B} \\
		\mathbf{B}^{T} & 0
	      \end{array} \right)
	\left(\begin{array} {c}
	      \mathbf{x} \\
		\mathbf{\lambda}
	      \end{array} \right) =
	\left( \begin{array} {c}
	       \mathbf{L} \\
		0
	       \end{array}\right)
\label{.e.xnorm}
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Unknown constraints}

The Newstar routines to handle this situation use a method based on
``Pseudo-inverse berekening en Cholesky factorisatie'', Hans van der Marel,
27 maart 1990. I will briefly describe Hans' paper, together with the
additions I have made.

In the case we are considering, the normal equation $\mathbf{A}$ has not full
column rank. Therefore, there exists, if the rank defect is $p$, an $n\times
p$ matrix $\mathbf{G}$, a basis for the null-space of $\mathbf{A}$, with
$\mathbf{AG}=0$. If we assume that $\mathbf{B}$ has just sufficient
constraint equations to solve the rank defect, the inverse of the matrix in
\eqref{.e.xnorm} is:
\begin{equation}
	{\left(\begin{array} {cc}
	      \mathbf{A} & \mathbf{B} \\
		\mathbf{B}^{T} & 0
	      \end{array} \right)}^{-1} =
	\left(\begin{array} {cc}
		\mathbf{A}^{\#} &
		\mathbf{G} {\left(\mathbf{B}^{T}\mathbf{G}\right)}^{-1} \\
		{\left(\mathbf{G}^{T}\mathbf{B}\right)}^{-1}\mathbf{G}^{T} & 0
	      \end{array}\right)
\end{equation}
with $\mathbf{A}^{\#}$ the pseudo-inverse of $\mathbf{A}$. A number of
relations hold for $\mathbf{A}^{\#}$, the most important for us that
$\mathbf{B}^{T}\mathbf{A}^{\#}=0$ and $\mathbf{A}^{\#}\mathbf{B}=0$, or
$\mathbf{B}$ is a base for the null-space of $\mathbf{A}^{\#}$. For a mininorm
solution we can choose $\mathbf{B}=\mathbf{G}$. In that case $\mathbf{A}^{\#}$
is the Moore-Penrose inverse, and $\mathbf{B}^{T}\mathbf{G}$ is regular and
symmetric.

We can now proceed in the following way:

\begin{enumerate}
	\item Do a Cholesky factorisation of the normal
equations $\mathbf{A}$ until the remaining columns of $\mathbf{A}$ are
dependent. Pivoting along the diagonal of $\mathbf{A}$ occurs to make sure
that $\mathbf{A}$ can be partitioned in an independent and a dependent part
with rank
defect $n_{2}$. Dependency is determined by looking at the angle between a
column and the space formed by the already determined independent space (the
so-called `collinearity number').

If $n_{1}=n-n_{2}$, we can say that after $n_{1}$ Choleski steps, we have:
\begin{equation}
	\mathbf{A} = \left( \begin{array} {cc}
			    A_{11} & A_{12} \\
				A_{21} & A_{22}
			    \end{array} \right) =
	\left( \begin{array} {cc}
		U_{11}^{T} & 0 \\
		U_{12}^{T} & I
	\end{array} \right) \cdot
	\left( \begin{array} {cc}
		U_{11} & U_{12} \\
		0 & \overline{A}_{22}
	\end{array} \right)
\end{equation}
with $U_{11}$ the Cholesky factor of $A_{11}$, $U_{12}={U_{11}^{T}}^{-1}
A_{12}$ and $\overline{A}_{22}=A_{22}-U_{12}^{T}U_{12}$.

The collinearity angle $\delta$ can be determined for the current column $i$
by: $\sin^{2}\delta = u_{ii}^{2}/a_{ii}$. \Mn
	\item Determine a $G_{1}$ replacing the (rectangular) $U_{12}$ from
$U_{11} G_{1} = -U_{12}$. \Mn
	\item Determine a (symmetric) $G_{2}$ replacing $A_{22}$ from the
rank basis $I+G_{1}^{T}G_{1} = (G_{2}^{T}-1)(G_{2}-1)$ \Mn
	\item determine constraint equations
$G={\left( G_{1}G_{2},G_{2}\right)}^{T}$. \Mn
	\item Solve for the $n_{1}$ independent unknowns $\mathbf{x}_{1}$
using $A_{11}$ and $L_{1}$ by back substitution \Mn
	\item Solve constraint equations for the remaining $n_{2}$ unknowns,
using $G_{2}$ by back substitution:
$\mathbf{x}_{2}=-G_{2}^{-1}G_{1}^{T}\mathbf{x}_{1}$ \Mn
	\item Make Baarda's S-transform of independent $n_{1}$ unknowns:
$\mathbf{x}_{1}=\mathbf{x}_{1}+G_{1}\mathbf{x}_{2}$. \Mn
\end{enumerate}
Setting $\mathbf{F}=A_{1}^{-1}L_{1}$, $\mathbf{D}=-G_{2}^{-1}G_{1}^{T}$
and $\mathbf{E} = \left(\begin{array}{c}\mathbf{I}_{n_{1}}+G_{1}\mathbf{D} \\
\mathbf{D}              \end{array}\right)$, we can write the above steps as:
\begin{equation}
	\left(\begin{array}{c}
		\mathbf{x}_{1} \\ \mathbf{x}_{2}
	      \end{array}\right) =
	\left(\begin{array}{c}
	      \mathbf{I}_{n_{1}}+G_{1}\mathbf{D} \\ \mathbf{D}
	      \end{array}\right)
	\left(\begin{array}{c}
	      A_{1}^{-1}L_{1}
	      \end{array}\right) = \mathbf{E}\cdot\mathbf{F}
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Errors}

Errors are determined in the same way as \textref{described in}{.ss.errors},
where it should be noted that \eqref{.e.chis3} can
either be used summing over $n_{1}$ variables and using the first guess of
$\mathbf{x}_{1}$, or over $n$ and using the final $\mathbf{x}$. Internally
the first option is used.
The uncertainties in $\mathbf{x}$ are determined by calculating the
covariance matrix. Using similar arithmetic \textref{as in}{.ss.errors}, it
can be shown that:
\begin{equation}
	\mathbf{A}^{-1}=\mathbf{E}\cdot\mathbf{a}_{1}^{-1}\cdot\mathbf{E}^{T}
\end{equation}
$\mathbf{A}^{-1}$ is calculated by first solving
$\mathbf{H}=\mathbf{E}\left(\mathbf{A}_{1}^{-1}
\cdot\mathbf{I}_{n_{1}}\right)$
and then $\mathbf{A}^{-1} = \mathbf{E}\cdot\mathbf{H}^{T}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Newstar calls}

The implementation in Newstar of dependent equations adds only one routine
WNMLTR, which replaces in this case the
\textref{call to WNMLTN in}{.ss.ncalls} and \textref{in}{.ss.ccalls}. The
call is:
\begin{itemize}
\item Do Cholesky factorisation of underdetermined system:\\
	\Logic\ WNMLTR(\LSQ,\Rank) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Rank] return \Int, the rank of $\mathbf{A}$. Note that in the
complex cases the maximum rank is $2n$. \Mn
\end{list}
\end{itemize}

All other calls remain identical, i.e. WNMLSN knows if a rank defect was
detected by WNMLTR. The actual constraint equations used in the solution can
be obtained by:
\begin{itemize}
\item Get constraint equations: \\
	CALL WNMLGC(\LSQ,\Nconst,\Constraint) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Nconst] the \Int\ number of constraint equations returned,
i.e. the rank deficiency \Mn
	\item[\Constraint] the \Real\ (or \Complex) constraint equations,
returned as an \\array($0:n-1,0:\,$\Nconst$\,-\,1,0:m-1$) \Mn
\end{list}
Note that in the complex case \Nconst\ can have a maximum value of $2n$, and
the returned equations are in {{\sc lsq}\_{\sc c}\_{\sc real}} type.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Known constraints}

In the case of known constraints, hence when $\mathbf{B}$ is known in
\eqref{.e.xnorm}, this equation can be solved. Cholesky decomposition
does not work in this case, and a, transparent, Crout LU decomposition is
done to determine the (symmetric) covariance (i.e. inverse) matrix of the
left hand side of \eqref{.e.xnorm}.
.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Errors}

Errors are determined as \textref{explained in}{.ss.errors}. Since all
constraint equations are $\equiv 0$, the sum in \eqref{.e.chis3} is
taken over $n$, not over $n+p$ if $p$ are the number of constraint equations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Newstar calls}

The basic differences with the normal procedures are:
\begin{enumerate}
\item the \LSQ-object should know the number of constraint equations \Mn
\item the constraint equations ($\mathbf{B}^{T}$) should be specified. \Mn
\end{enumerate}

The calls that are necessary:
\begin{enumerate}
\item generate an \LSQ-object with:\\
	\Logic\ WNMLGA(\LSQ, \Type, $n$\ , $m$, $p$) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \Int, return pointer to created \LSQ-object
(if {\em .true.}) \Mn
	\item[\Type] coded \Int; coded as:\\
\{ {{\sc lsq}\_{\sc t}\_{\sc real}}\ $|$\ {{\sc lsq}\_{\sc t}\_{\sc
complex}}\}
\ +\ {{\sc lsq}\_{\sc t}\_{\sc constraints}} \\
{[}+\ {{\sc lsq}\_{\sc t}\_{\sc multiple}}].\\
The second part indicates that multiple \mbox{($m > 1$)} simultaneous equations
are
requested.  \Mn
	\item[$n$]  \Int, number of unknowns \Mn
	\item[$m$]  \Int, number of simultaneous equations if
{{\sc lsq}\_{\sc t}\_{\sc multiple}} specified or 0 (default one) \Mn
	\item[$p$]  \Int, number of constraint equations \Mn
\end{list}
\item specify the constraint equations with a call to:\\
	CALL WNMLMC(\LSQ, \Type, \Constraint) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Type] coded \Int\ with same values as WNMLMN. In the complex
case and \Complex\ type, the number of equations given should be $p/2$.
that the constraint equations are real \Mn
	\item[\Constraint] constraint equations as \Real($0:n-1,0:p-1$)\\
 or as {\Complex($0:n-1,0:p/2-1$)} or as \Real($0:2n-1,0:p-1$)\\
 or as {\Complex($0:2n-1,0:p/2-1$)}, depending on \Type\Mn
\end{list}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Non-linear equations}

In the case of non-linear condition equations, no simple solution to minimise
the merit function (e.g. \eqref{.e.chir}) exists. A simple solution
is to take the condition equation, make a first order Taylor expansion around
an estimated $\hat{\mathbf{x}}$; solve for $d\mathbf{x}$, and iterate till
solution found. This approach was used in Newstar originally.

However, better and more stable methods exist (e.g. steepest-descend) for
some circumstances. A method that seems to be quite stable and using both
steepest-descent and Taylor expansion, is the method by Levenberg-Marquardt
(see e.g. ``Numerical recipes'', W.H. Press {\em et al.}, Cambridge
University Press).

If we have an estimate for $\mathbf{x}$, we can find a better one by:
\begin{equation}
	\hat{\mathbf{x}}_{next}=\hat{\mathbf{x}}+\mathbf{H}^{-1}\cdot
		\left[ -\nabla\chi^{2}(\hat{\mathbf{x}})\right]
\label{.e.nonl1}
\end{equation}
where $\mathbf{H}$ is the Hessian matrix of $\chi^{2}$. If our approximation
is not good enough, we could use the steepest-descent by calculating:
\begin{equation}
	\hat{\mathbf{x}}_{next}=\hat{\mathbf{x}}-\mathit{constant}\cdot
		\left[ -\nabla\chi^{2}(\hat{\mathbf{x}})\right]
\label{.e.nonl2}
\end{equation}

The Hessian matrix $\mathbf{H}$ has as elements:
\begin{equation}
	H_{ij} =
	\frac{\partial^{2}\chi^{2}}{\partial x_{i}\partial x_{j}} =
	2\sum_{k=0}^{N-1}\frac{1}{\sigma_{i}^{2}} \left[
		\frac{\partial y_{k}}{\partial x_{i}}
		\frac{\partial y_{k}}{\partial x_{j}}-
		\left( l_{i}-y_{i}\right)
		\frac{\partial^{2}y_{i}}{\partial x_{i} \partial x_{j}}\right]
\label{.e.hes}
\end{equation}
By dropping the second term in \eqref{.e.hes}, and multiplying each
$H_{ii}$ term with $(1+\lambda)$, and defining the first derivative of
$\chi^{2}$ as $\mathbf{b}$, we can combine the equations \eqref{.e.nonl1},
\eqref{.e.nonl2} into:
\begin{equation}
	\mathbf{H}\cdot d\mathbf{x} = \mathbf{b}
\end{equation}
which can be solved as standard normal equations.

Choosing $\lambda$ is the crux of the matter, and where to stop iterating. A
start value of $\lambda=0.001$ is used in the following routines. The method
looks at the $\chi^{2}$ for $\hat{\mathbf{x}}+d\mathbf{x}$. If it has increased
over the value of $\chi^{2}$ for $\hat{\mathbf{x}}$, $\hat{\mathbf{x}}$ is
unchanged, and $\lambda=10\lambda$. If there is a decrease; a new value for
$\hat{\mathbf{x}}$ is used, and $\lambda=\lambda / 10$. Iteration can be
stopped if the fractional decrease in $\chi^{2}$ is small (say $<0.001$);
never if there is an increase in $\chi^{2}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Errors}

Errors are calculated as \textref{described in}{.ss.errors}. The errors
returned by WNMLSN are, of course, only approximations, since the original
equations are non-linear, but give a good impression of the residuals. The
covariance matrix should be calculated by doing a final linear run on the
residuals, and solve the equations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Newstar calls}

The basic difference in calls is the use of WNMLNN(or in special cases maybe
WNMLNR)  rather than WNMLTN to
triangularise the normal matrix. The
condition equations should contain the derivative to the $x_{k}$ at the
position of $\hat{\mathbf{x}}$; and the measured values the value
$\left(l_{i}-y_{i}(\hat{\mathbf{x}})\right)$.

The actual steps in the process are than:
\begin{enumerate}
\item create \LSQ-object with WNMLGA (note that {{\sc lsq}\_{\sc t}\_{\sc
multiple}} is not allowed) \Mn
\item fill it with condition equations, as
\textref{described in}{.ss.ncalls} or \textref{in}{.ss.ccalls}, with WNMLMN,
using the residuals with an
estimated solution as the $l$-terms, and the derivative with respect to the
unknowns of the condition equations as the condition equations \Mn
\label{.ll.2}
\item triangularise and solve with:\\
	\Logic\ WNMLNN(\LSQ,0,\Sol,\Error,\Fit) or:\\
	\Logic\ WNMLNR(\LSQ,\Rank,\Sol,\Error,\Fit)  with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Rank] return \Int, the rank of $\mathbf{A}$. Note that in the
complex case the maximum rank is $2n$. \Mn
	\item[\Sol] the estimated solution should be given, and will be
updated to a new solution of $\mathbf{x}$ as \Real($0:n-1$) or
\Complex($0:n-1$) \Mn
	\item[\Error] adjustment error per unit weight ($\sigma_{w}$)as
\Real \Mn
	\item[\Fit] goodness of current estimate as \Real. If \Fit\ $>0$ no
stable solution reached yet; if \Fit\ $\leq 0$ and $|$\Fit$|<0.001$ the
process can be stopped. \Fit\ is the fractional improvement in $\chi^{2}$.  \Mn
\end{list}
\item check the \Fit\ returned parameter. If it is non-positive and has an
absolute  value less than what you think is a good change (e.g. 0.001) stop
the process \Mn
\item else re-start at \ref{.ll.2} \Mn
\item if satisfied, and the covariance matrix is wanted, re-initialise the
\LSQ-object with {{\sc lsq}\_{\sc i}\_{\sc all}}, reload condition equations,
use \mbox{WNMLTR} (or WNMLTN if you are sure of an independent set of
equations), and ask for the  covariance matrix or vector (WNMLCV or
\mbox{WNMLME}). \Mn
\item free \LSQ-object with WNMLFA  \Mn
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary}

An \LSQ-object takes a total space of:
\begin{eqnarray}
9 & + & (\mathrm{administration}) \nonumber \\
(n+p)(n+p+1)/2 & + & (\mathrm{normal\ array}) \nonumber \\
4m & + & (\mathrm{error\ calculations}) \nonumber \\
m(m+p) & + & (\mathrm{known\ sides}) \nonumber \\
(n+p+1)/2 & + & (\mathrm{pivot\ area}) \nonumber \\
(n+p) & & (\mathrm{solution})\ \mathrm{8\ byte\ words}
\end{eqnarray}
where $n$ is the number of unknowns ($2n$ if complex); $m$ the number of
simultaneously to be
solved equations; $p$ the number of external constraint equations.
In the non-linear case two \LSQ-objects are used. In cases where the inverted
normal array is calculated (known constraints, or explicit calls to WNMLME,
WNMLCV or WNMLIN) a temporary storage of $n^{2}$ 8-byte words is used.

The following calls are available:
\begin{enumerate}
\item generate an \LSQ-object with:\\
	\Logic\ WNMLGA(\LSQ, \Type, $n$\ [, $m$[, $p$[, \Prec]]]) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \Int, return pointer to created \LSQ-object
(if {\em .true.})
	\item[\Type] coded \Int; coded as: 0 or
\{ {{\sc lsq}\_{\sc t}\_{\sc real}}\ $|$\
{{\sc lsq}\_{\sc t}\_{\sc complex}}\} (\Real\ is default if not specified)\\
+ one or more of the following optional ones:\\
	{{\sc lsq}\_{\sc t}\_{\sc multiple}} if $m$ present (else 1
assumed)\\
{\sc lsq}\_{\sc t}\_{\sc constraint} if $p$ present (else 0 assumed)\\
{\sc lsq}\_{\sc t}\_{\sc prec} if \Prec\ present (else default $10^{-6}$
assumed)\\
Optional trailing arguments may be omitted; embedded ones should have a
value, preferably ``0''.
	\item[$n$]  \Int, number of unknowns
	\item[$m$]  \Int, number of simultaneous equations if
{{\sc lsq}\_{\sc t}\_{\sc multiple}} specified (default 1)
	\item[$p$] \Int, number of user specified constraints if
{{\sc lsq}\_{\sc t}\_{\sc constraint}} (default 0)
	\item[\Prec] \Real, the value to be used in dependency checks
(default $10^{-6}$)
\end{list}

\item delete an \LSQ-object with:\\
	CALL WNMLFA(\LSQ) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \Int, pointer to \LSQ-object
\end{list}

\item re-initialise an existing \LSQ-object for re-use with: \\
	CALL WNMLIA(\LSQ, \Type\ [, \Prec]) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Type] coded \Int, coded as a combination of:
\begin{description}
	\item[--] 0: default, equal to {{\sc lsq}\_{\sc i}\_{\sc all}} \Mn
	\item[--] {{\sc lsq}\_{\sc i}\_{\sc norm}}: re-initialise the
`unknown' part of the object (i.e. the normal array $\mathbf{A}$) \Mn
	\item[--] {{\sc lsq}\_{\sc i}\_{\sc known}}: re-initialise the
`known' part of the object (i.e. the vector ${\mathbf L}$) \Mn
	\item[--] {{\sc lsq}\_{\sc i}\_{\sc sol}}: equal to
{\sc norm}\ +\ {\sc known} \Mn
	\item[--] {{\sc lsq}\_{\sc i}\_{\sc nonlin}}: re-initialise the
non-linear part of the object \Mn
	\item[--] {{\sc lsq}\_{\sc i}\_{\sc all}}: equal to
{\sc sol}\ +\ {\sc nonlin} \Mn
	\item[--] {{\sc lsq}\_{\sc i}\_{\sc prec}}: set the internal check
precision to \Prec \Mn
\end{description}
	\item[\Prec] precision factor to be used (\Real). Only used if
{{\sc lsq}\_{\sc i}\_{\sc prec}} set. Note that the default internal value is
$10^{-6}$.  \Mn
\end{list}

\item generate normal equations from the condition equations with successive
calls to:\\
	CALL WNMLMN(\LSQ, \Type, \Cond, \Weight, \Known) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Type] coded \Int, coded in the real case as one of :
\begin{description}
	\item[--] 0: default, equal to {{\sc lsq}\_{\sc c}\_{\sc real}} \Mn
	\item[--] {{\sc lsq}\_{\sc c}\_{\sc real}} condition equations have
\Real$(0:n-1)$ values
\end{description}
or in the complex case as one of:
\begin{description}
	\item[--] 0: default, equal to {{\sc lsq}\_{\sc c}\_{\sc complex}} \Mn
	\item[--] {{\sc lsq}\_{\sc c}\_{\sc real}} condition equations have
\Real$(0:2n-1)$ values
	\item[--] {{\sc lsq}\_{\sc c}\_{\sc complex}} condition equations have
\Complex$(0:n-1)$ values
	\item[--] {{\sc lsq}\_{\sc c}\_{\sc ccomplex}} condition equations have
\Complex$(0:2n-1)$ values for conjugate variables
	\item[--] {{\sc lsq}\_{\sc c}\_{\sc dcomplex}} condition equations have
\Complex$(0:2n-1)$ values for separate real and imaginary variables
\end{description}
in both cases it can be combined with one or more of:
\begin{description}
	\item[--] {{\sc lsq}\_{\sc c}\_{\sc nonorm}} to bypass updating the
normal array ($\mathbf{A}$)
	\item[--] {{\sc lsq}\_{\sc c}\_{\sc noknown}} to bypass updating the
known vector(s) ($\mathbf{L}$)
\end{description}
	\item[\Cond] factors in condition equation as \Real($0:n-1$),
\Real($0:2n-1$), \Complex($0:n-1$) or \Complex($0:2n-1$), depending on the
\Type \Mn
	\item[\Weight] \Real, weight of condition equation ($w=1/\sigma^2$).
Note that for the best arithmetic performance, the $w_{i}$ are best
normalised to a maximum value of one. \Mn
	\item[\Known] measured value(s) as \Real($0:m-1$) or
\Complex($0:m-1$) \Mn
\end{list}

\item specify known constraint equations with a call to:\\
	CALL WNMLMC(\LSQ, \Type, \Constraint) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Type] the same \Type\ as used in WNMLMN to indicate the type
of equations \Mn
	\item[\Constraint] constraint equations as \Real($0:n-1,0:p-1$) or as\\
{\Complex($0:n-1,0:p/2-1$)}, {\Complex($0:2n-1,0:p/2-1$)} or as\\
{\Real($0:2n-1,0:p-1$)}, depending on \Type \Mn
\end{list}

	\item prepare normal equations for solution with one of:\\
	\Logic\ WNMLTN(\LSQ) \\
	\Logic\ WNMLTR(\LSQ,\Rank) \\
	\Logic\ WNMLNN(\LSQ,0,\Sol,\Error,\Fit) \\
	\Logic\ WNMLNR(\LSQ,\Rank,\Sol,\Error,\Fit)  with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Rank] return \Int, the rank of $\mathbf{A}$. Note that in the
complex case the maximum rank is $2n$. \Mn
	\item[\Sol] the estimated solution should be given, and will be
updated to a new solution of $\mathbf{x}$ as \Real($0:n-1$) or
\Complex($0:n-1$) \Mn
	\item[\Error] adjustment error per unit weight ($\sigma_{w}$)as
\Real \Mn
	\item[\Fit] goodness of current estimate as \Real. If \Fit\ $>0$ no
stable solution reached yet; if \Fit\ $\leq 0$ and $|$\Fit$|<0.001$ the
process can be stopped. \Fit\ is the fractional improvement in $\chi^{2}$.  \Mn
\end{list}

WNMLTN assumes that the normal equations are fully determined; WNMLTR will
determine the minimum orthogonal set of constraint equations    necessary to
solve the normal equations; WNMLNN will solve an update to a solution \Sol
for non-linear condition equations; WNMLNR will solve as WNMLNN, but will
also calculate the set of constraints if necessary.

\item obtain the solution by back substitution for the non-linear case with:\\
	CALL WNMLSN(\LSQ,\Sol,\Error,\Mean) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Sol] solution $\mathbf{x}$ as \Real($0:n-1,0:m-1$) or
\Complex($0:n-1,0:m-1$)  \Mn
	\item[\Error] adjustment error per unit weight ($\sigma_{w}$)as
\Real($0:m-1$) \Mn
	\item[\Mean] standard deviation ($\sigma_{o}$) as \Real($0:m-1$) \Mn
\end{list}

\item get calculated constraint equations: \\
	CALL WNMLGC(\LSQ,\Nconst,\Constraint) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Nconst] the \Int\ number of constraint equations returned,
i.e. the (real) rank deficiency \Mn
	\item[\Constraint] the \Real\ (or \Complex) constraint equations,
returned as an \\array($0:n-1,0:\,$\Nconst$\,-\,1,0:m-1$) \Mn
\end{list}
Note that in the complex case \Nconst\ can have a maximum value of $2n$.

\item obtain the covariance matrix or something similar with:\\
	CALL WNMLME(\LSQ,\Xsd) or:\\
	CALL WNMLCV(\LSQ,\Covar) or:\\
	CALL WNMLIN(\LSQ) with:
\begin{list}{1}{\setlength{\labelwidth}{16em}}
	\item[\LSQ] \LSQ-object pointer \Mn
	\item[\Xsd] the uncertainties in the unknowns $\mathbf{x}$ as
\Real($0:n-1,0:m-1$) or as \Complex($0:n-1,0:m-1$)  \Mn
	\item[\Covar] the covariance (inverse) matrix of the solution, as \\
\Real($0:n-1,0:n-1$) or as \Real($0:2n-1,0:2n-1$) for the complex case \Mn
\end{list}
	WNMLIN will calculate the covariance matrix internally only. In all
three cases the covariance matrix will overwrite the normal array, and it
will be used, rather than back substitution, in WNMLSN if that routine is
called after one of the inversion ones. After an inversion call the
constraint
equations can no longer be obtained

\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{2cm}
{\em wnb, \today}
\end{document}                          %%%%% End of document %%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
